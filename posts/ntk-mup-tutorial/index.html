<!DOCTYPE html><html class="font-serif scroll-smooth" lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1,viewport-fit=cover" name=viewport><link href=/icons/godmode.png rel=icon type=image/png><title>Lazy (NTK) and active (muP) training -- what gives? | Dhruva&#39;s dumb website</title><meta content="There's only one degree of freedom in choosing how hyperparameters scale with network width." name=description><meta content="Dhruva Karkada" name=author><meta content="Astro v5.9.3" name=generator><meta content="oklch(0.20 0.036 280)" name=theme-color><link href=https://fonts.googleapis.com rel=preconnect><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap&" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,200..900;1,200..900&family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel=stylesheet><link href=/_astro/katex.min.COXD5gRV.css rel=preload as=style><link href=/_astro/photoswipe.cPPnkASS.css rel=stylesheet media=print onload="this.media=&#34;all&#34;"><link href=/_astro/katex.min.COXD5gRV.css rel=stylesheet media=print onload="this.media=&#34;all&#34;"><link href=/rss.xml rel=alternate type=application/rss+xml title="RSS Feed"><link href=/atom.xml rel=alternate type=application/atom+xml title="Atom Feed"><link href=/sitemap-index.xml rel=sitemap><link href=https://dkarkada.xyz/posts/ntk-mup-tutorial/ rel=canonical><meta content=article property=og:type><meta content=https://dkarkada.xyz/posts/ntk-mup-tutorial/ property=og:url><meta content="Lazy (NTK) and active (muP) training -- what gives? | Dhruva's dumb website" property=og:title><meta content="There's only one degree of freedom in choosing how hyperparameters scale with network width." property=og:description><meta content=https://dkarkada.xyz/og/blog/2024-10-08-richness.png property=og:image><meta content=summary_large_image name=twitter:card><meta content=@dhruvakarkada name=twitter:site><meta content=true name=astro-view-transitions-enabled><meta content=none name=astro-view-transitions-fallback><script type=module src=/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CLDwYp7M.js></script><script>!function(){function e(e=document){const t=function(){const e=localStorage.getItem("theme");return!e||"dark"===e}();e.documentElement.classList.toggle("dark",t);const n=e.head.querySelector('meta[name="theme-color"]');n?.setAttribute("content",t?"oklch(0.20 0.036 280)":"oklch(96% 0.005 298)")}function t(e=document){const t=window.matchMedia("(prefers-reduced-motion: reduce)").matches||!("startViewTransition"in e);e.documentElement.classList.toggle("reduce-motion",t),e.documentElement.classList.add("js")}e(),t(),document.addEventListener("astro:before-swap",(({newDocument:n})=>{e(n),t(n)})),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",(({matches:t})=>{localStorage.setItem("theme",t?"dark":"light"),e(),document.dispatchEvent(new Event("theme-changed"))}))}()</script><link href=/_astro/_index_.BiDrjJpm.css rel=stylesheet><link href=/_astro/_posts_slug_.xFqqKmxR.css rel=stylesheet><style>@keyframes astroFadeInOut{0%{opacity:1}to{opacity:0}}@keyframes astroFadeIn{0%{opacity:0;mix-blend-mode:plus-lighter}to{opacity:1;mix-blend-mode:plus-lighter}}@keyframes astroFadeOut{0%{opacity:1;mix-blend-mode:plus-lighter}to{opacity:0;mix-blend-mode:plus-lighter}}@keyframes astroSlideFromRight{0%{transform:translate(100%)}}@keyframes astroSlideFromLeft{0%{transform:translate(-100%)}}@keyframes astroSlideToRight{to{transform:translate(100%)}}@keyframes astroSlideToLeft{to{transform:translate(-100%)}}@media (prefers-reduced-motion){::view-transition-group(*),::view-transition-new(*),::view-transition-old(*){animation:none!important}[data-astro-transition-scope]{animation:none!important}}</style><script type=module src=/_astro/page.BNYwb576.js></script><script>!function(t,e,n,r){(window.crossOriginIsolated||navigator.serviceWorker)&&((r=t[e]=Object.assign(t[e]||{},{lib:"/~partytown/",debug:!1}))[n]=(r[n]||[]).concat(["dataLayer.push","gtag"]))}(window,"partytown","forward");const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((()=>{const t=new Set;let e=[];do{Object.getOwnPropertyNames(e).forEach((n=>{"function"==typeof e[n]&&t.add(n)}))}while((e=Object.getPrototypeOf(e))!==Object.prototype);return Array.from(t)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function y(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(h,(null==s?void 0:s.fallbackTimeout)||1e4),r.addEventListener("pt0",b),a?w(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?w():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&w()}))}),console.error):h())))}function w(e){p=r.createElement(e?"script":"iframe"),t._pttab=Date.now(),e||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(e?"atomics.js?v=0.11.1":"sandbox-sw.html?"+t._pttab),r.querySelector(s.sandboxParent||"body").appendChild(p)}function h(n,o){for(b(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function b(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?y():(t.addEventListener("DOMContentLoaded",y),t.addEventListener("load",y))}(window,document,navigator,top,window.crossOriginIsolated),document.addEventListener("astro:before-swap",(t=>{let e=document.body.querySelector("iframe[src*='/~partytown/']");e&&t.newDocument.body.append(e)}))</script><style>[data-astro-transition-scope=astro-va26yt7w-1]{view-transition-name:post-ntk-mup-tutorial}@layer astro{::view-transition-old(post-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}::view-transition-new(post-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}[data-astro-transition=back]::view-transition-old(post-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}[data-astro-transition=back]::view-transition-new(post-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}}[data-astro-transition-fallback=old] [data-astro-transition-scope=astro-va26yt7w-1],[data-astro-transition-fallback=old][data-astro-transition-scope=astro-va26yt7w-1]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}[data-astro-transition-fallback=new] [data-astro-transition-scope=astro-va26yt7w-1],[data-astro-transition-fallback=new][data-astro-transition-scope=astro-va26yt7w-1]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}[data-astro-transition=back][data-astro-transition-fallback=old] [data-astro-transition-scope=astro-va26yt7w-1],[data-astro-transition=back][data-astro-transition-fallback=old][data-astro-transition-scope=astro-va26yt7w-1]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}[data-astro-transition=back][data-astro-transition-fallback=new] [data-astro-transition-scope=astro-va26yt7w-1],[data-astro-transition=back][data-astro-transition-fallback=new][data-astro-transition-scope=astro-va26yt7w-1]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}</style><style>[data-astro-transition-scope=astro-aqc54ihn-2]{view-transition-name:time-ntk-mup-tutorial}@layer astro{::view-transition-old(time-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}::view-transition-new(time-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}[data-astro-transition=back]::view-transition-old(time-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}[data-astro-transition=back]::view-transition-new(time-ntk-mup-tutorial){animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}}[data-astro-transition-fallback=old] [data-astro-transition-scope=astro-aqc54ihn-2],[data-astro-transition-fallback=old][data-astro-transition-scope=astro-aqc54ihn-2]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}[data-astro-transition-fallback=new] [data-astro-transition-scope=astro-aqc54ihn-2],[data-astro-transition-fallback=new][data-astro-transition-scope=astro-aqc54ihn-2]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}[data-astro-transition=back][data-astro-transition-fallback=old] [data-astro-transition-scope=astro-aqc54ihn-2],[data-astro-transition=back][data-astro-transition-fallback=old][data-astro-transition-scope=astro-aqc54ihn-2]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeOut}[data-astro-transition=back][data-astro-transition-fallback=new] [data-astro-transition-scope=astro-aqc54ihn-2],[data-astro-transition=back][data-astro-transition-fallback=new][data-astro-transition-scope=astro-aqc54ihn-2]{animation-duration:180ms;animation-timing-function:cubic-bezier(0.76,0,0.24,1);animation-fill-mode:both;animation-name:astroFadeIn}</style></head><div id=noise-overlay></div><div class="relative w-full max-w-205.848 min-h-dvh min-h-vh mx-auto" lg="mx-[max(5.75rem,calc(50vw-34.25rem))] my-20 max-w-[min(calc(75vw-16rem),44rem)] min-h-full p-0" p="x-[min(7.25vw,3.731rem)] y-10"><style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(self.Astro||(self.Astro={})).load=async a=>{await(await a())()},window.dispatchEvent(new Event("astro:load"))</script><script>(()=>{var t=Object.defineProperty,e=(e,r,n)=>((e,r,n)=>r in e?t(e,r,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[r]=n)(e,"symbol"!=typeof r?r+"":r,n);{let t={0:t=>s(t),1:t=>n(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(n(t)),5:t=>new Set(n(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},r=e=>{let[r,n]=e;return r in t?t[r](n):void 0},n=t=>t.map(r),s=t=>"object"!=typeof t||null===t?t:Object.fromEntries(Object.entries(t).map((([t,e])=>[t,r(e)])));class i extends HTMLElement{constructor(){super(...arguments),e(this,"Component"),e(this,"hydrator"),e(this,"hydrate",(async()=>{var t;if(!this.hydrator||!this.isConnected)return;let e=null==(t=this.parentElement)?void 0:t.closest("astro-island[ssr]");if(e)return void e.addEventListener("astro:hydrate",this.hydrate,{once:!0});let r,n=this.querySelectorAll("astro-slot"),i={},o=this.querySelectorAll("template[data-astro-template]");for(let t of o){let e=t.closest(this.tagName);null!=e&&e.isSameNode(this)&&(i[t.getAttribute("data-astro-template")||"default"]=t.innerHTML,t.remove())}for(let t of n){let e=t.closest(this.tagName);null!=e&&e.isSameNode(this)&&(i[t.getAttribute("name")||"default"]=t.innerHTML)}try{r=this.hasAttribute("props")?s(JSON.parse(this.getAttribute("props"))):{}}catch(t){let e=this.getAttribute("component-url")||"<unknown>",r=this.getAttribute("component-export");throw r&&(e+=` (export ${r})`),console.error(`[hydrate] Error parsing props for component ${e}`,this.getAttribute("props"),t),t}await this.hydrator(this)(this.Component,r,i,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))})),e(this,"unmount",(()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))}))}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(this.hasAttribute("await-children")&&"interactive"!==document.readyState&&"complete"!==document.readyState){let t=()=>{document.removeEventListener("DOMContentLoaded",t),e.disconnect(),this.childrenConnectedCallback()},e=new MutationObserver((()=>{var e;(null==(e=this.lastChild)?void 0:e.nodeType)===Node.COMMENT_NODE&&"astro:end"===this.lastChild.nodeValue&&(this.lastChild.remove(),t())}));e.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",t)}else this.childrenConnectedCallback()}async childrenConnectedCallback(){let t=this.getAttribute("before-hydration-url");t&&await import(t),this.start()}async start(){let t=JSON.parse(this.getAttribute("opts")),e=this.getAttribute("client");if(void 0!==Astro[e])try{await Astro[e]((async()=>{let t=this.getAttribute("renderer-url"),[e,{default:r}]=await Promise.all([import(this.getAttribute("component-url")),t?import(t):()=>()=>{}]),n=this.getAttribute("component-export")||"default";if(n.includes(".")){this.Component=e;for(let t of n.split("."))this.Component=this.Component[t]}else this.Component=e[n];return this.hydrator=r,this.hydrate}),t,this)}catch(t){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,t)}else window.addEventListener(`astro:${e}`,(()=>this.start()),{once:!0})}attributeChangedCallback(){this.hydrate()}}e(i,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",i)}})()</script><astro-island await-children client=load component-export=default component-url=/_astro/Anim.OuElsjs2.js opts={&quot;name&quot;:&quot;Anim&quot;,&quot;value&quot;:true} prefix=r1 props={&quot;isAbout&quot;:[0,false],&quot;isHome&quot;:[0,false]} renderer-url=/_astro/client.BPIbHqJh.js ssr uid=2u3Au4><div class="animContainer lg:uno-desktop-column w-14em"><canvas class=animCanvas height=50 width=50></canvas></div><!--astro:end--></astro-island><nav aria-label="Site Navigation" class="hidden font-italic font-navbar font-semibold leading-2.45em lg:block lg:bottom-[min(9.04rem+3.85vw,10.5rem)] lg:text-5 lg:uno-desktop-column mb-10.5 text-3.6"><ul><li><a href=/ class="c-primary after:bottom-0.7em font-bold highlight-static">Posts</a></li><li><a href=/tags/ class="highlight-hover hover:c-primary after:bottom-0.7em hover:font-bold transition-[colors,font-weight]">Tags</a></li></ul></nav><main class=mb-12><article class="heti mb-12.6"><div class=relative><button aria-label="Go back" class=hidden id=back-button lg="absolute left--10 top-3.8 block aspect-square w-4.5 c-secondary/40 transition-colors ease-out hover:c-secondary/80 active:scale-90!"><svg aria-hidden=true fill=currentColor viewBox="0 0 24 24"><path d=M17.8.7L4,12l13.8,11.4.7-.9L7.2,12,18.5,1.5l-.7-.8Z /></svg></button><script type=module>function t(){document.getElementById("back-button")?.addEventListener("click",(()=>{window.history.length>1?window.history.back():document.getElementById("site-title-link")?.click()}))}t(),document.addEventListener("astro:after-swap",t)</script><h1 class=post-title><span data-astro-transition-scope=astro-va26yt7w-1 data-disable-theme-transition>Lazy (NTK) and active (muP) training -- what gives?</span></h1></div><div class="c-primary block font-time mb-17.2" id=gsap-post-date data-astro-transition-scope=astro-aqc54ihn-2 data-disable-theme-transition><time datetime=2024-10-06>6 Oct 2024 </time><span class=ml-1.75>6 min</span></div><div class="2xl:bg-secondary/0 2xl:border-none 2xl:fixed 2xl:left-0 2xl:max-w-[min(calc(50vw-38rem),13rem)] 2xl:top-44.5 bg-secondary/5 mb-6 uno-round-border" data-astro-cid-v5otsao3 id=toc-container><input data-astro-cid-v5otsao3 hidden id=toc-toggle type=checkbox><div class="relative w-full h-12" data-astro-cid-v5otsao3><label class="flex absolute inset-0 items-center 2xl:c-secondary/40 2xl:ease-out 2xl:flex 2xl:hover:c-secondary/80 2xl:static 2xl:transition-colors cursor-pointer" data-astro-cid-v5otsao3 for=toc-toggle><span data-astro-cid-v5otsao3 id=toc-mobile-text>Table of Contents</span><svg aria-hidden=true fill=currentColor viewBox="0 0 24 24" class="hidden 2xl:active:scale-90! 2xl:block 2xl:mt-4 2xl:origin-center aspect-square ml-4 w-4.2" data-astro-cid-v5otsao3=true id=toc-desktop-icon><path d="M22.2 2.3H1.8V4h19.9zM22.2 20H1.8v1.7h19.9zM15.5 11.2H1.8v1.6H15z"/></svg></label></div><div id=toc-accordion-wrapper data-astro-cid-v5otsao3><nav aria-label="Table of Contents" data-astro-cid-v5otsao3 id=toc-accordion-content><ul data-astro-cid-v5otsao3 id=toc-links-list><li class=ml-0 data-astro-cid-v5otsao3><a href=#whats-so-tricky-about-infinite-width-networks class="highlight-hover toc-links-h2" data-astro-cid-v5otsao3>What’s so tricky about infinite-width networks?</a></li><li class=ml-0 data-astro-cid-v5otsao3><a href=#formalizing-the-training-desiderata class="highlight-hover toc-links-h2" data-astro-cid-v5otsao3>Formalizing the training desiderata</a></li><li class=ml-0 data-astro-cid-v5otsao3><a href=#gauge-symmetries-and-parameterizations-galore class="highlight-hover toc-links-h2" data-astro-cid-v5otsao3>Gauge symmetries and parameterizations galore</a></li><li class=ml-0 data-astro-cid-v5otsao3><a href=#footnote-label class="highlight-hover toc-links-h2" data-astro-cid-v5otsao3>Footnotes</a></li></ul></nav></div></div><script type=module>function g(){if(!(window.innerWidth>=1536))return;const t=document.getElementById("toc-accordion-content");if(!t)return;const e=t.getElementsByTagName("a");if(0===e.length)return;const n=Array.from(e,(t=>t)),o=n.some((t=>t.classList.contains("toc-links-h2")))?"toc-links-h2":"toc-links-h3",s=new Map;n.forEach((t=>{const e=t.getAttribute("href")?.substring(1);e&&s.set(e,t)}));let i=null;function c(t){t!==i&&(n.forEach((t=>{t.classList.remove("toc-link-active")})),t.classList.add("toc-link-active"),t.classList.contains(o)||function(t){for(let e=n.indexOf(t)-1;e>=0;e--){const t=n[e];if(t.classList.contains(o)){t.classList.add("toc-link-active");break}}}(t),i=t,t.scrollIntoView({behavior:"smooth",block:"nearest"}))}const r=new IntersectionObserver((t=>{const e=t.find((t=>t.isIntersecting))?.target?.id;if(e){const t=s.get(e);t&&c(t)}}),{rootMargin:"0% 0% -66% 0%",threshold:[.4]});Array.from(document.querySelectorAll("h2, h3, h4")).filter((t=>t.id&&"footnotes"!==t.id)).forEach((t=>r.observe(t))),n.length>0&&c(n[0]);const a=document.getElementById("gsap-post-content"),l=a?.lastElementChild;a&&l&&new IntersectionObserver((t=>{!t[0].isIntersecting&&t[0].boundingClientRect.top<0&&(n.forEach((t=>t.classList.remove("toc-link-active"))),i=null)}),{rootMargin:"0px 0px 0px 0px",threshold:0}).observe(l)}g(),document.addEventListener("astro:after-swap",g)</script><div id=gsap-post-content><p><a href=https://arxiv.org/abs/2404.19719 rel="nofollow noopener noreferrer external" target=_blank>Paper link.</a></p><p>A central theme of the modern machine learning paradigm is that larger neural networks achieve better performance. One particularly useful kind of largeness is the network <em>width</em>, i.e., the dimension of the hidden representations. To understand the learning mechanisms in wide networks, we should aim to first understand the limiting behavior — what happens at infinite width? But training infinitely wide networks isn’t a walk in the park — infinity is a bit of a trickster, and we should be cautious around him.</p><p>As it turns out, in order to train infinitely wide networks well, there’s only <em>one</em> effective degree of freedom in choosing how to scale hyperparameters such as the learning rate and the size of the initial weights. This degree of freedom controls the <em>richness</em> of training behavior: at minimum, the wide network trains lazily like a kernel machine, and at maximum, it exhibits feature learning in the active <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>μ</mi><mi mathvariant=normal>P</mi></mrow><annotation encoding=application/x-tex>\mu\mathrm{P}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class="mord mathnormal">μ</span><span class="mord mathrm">P</span></span></span></span> regime. I recently wrote a review paper (see link above) giving a straightforward derivation of this fact. This paper was a product of my own effort to navigate the literature on wide networks, which I personally found unclear. In this blog post, I’ll just cover the main ideas.</p><h2 id=whats-so-tricky-about-infinite-width-networks>What’s so tricky about infinite-width networks?<a href=#whats-so-tricky-about-infinite-width-networks class=heading-anchor-link aria-label="Link to What’s so tricky about infinite-width networks?"><svg aria-hidden=true fill=currentColor viewBox="0 0 24 24"><path d="M2.6 21.4c2 2 5.9 2.9 8.9 0l3.5-3.5-1-1-3.5 3.5c-1.4 1.4-4.2 1.9-6.4-.3s-1.8-5-.3-6.4l3.5-3.5-1-1-3.5 3.5c-3 3-2 6.9 0 8.9ZM21.4 2.6c2 2 2.9 5.9 0 8.9L17.9 15l-1-1 3.5-3.5c1.4-1.4 1.9-4.2-.3-6.4s-5-1.8-6.4-.3l-3.5 3.5-1-1 3.5-3.5c3-3 6.9-2 8.9 0Z"></path><path d="m8.01 14.97 6.93-6.93 1.061 1.06-6.93 6.93z"></path></svg></a></h2><p>Feedforward (supervised) nets are relatively simple architectures: there’s a forward pass, where predictive signal flows from input to output, and a backpropagating gradient, where error signal flows from output to input. Training models just consists of repeating this process a bunch of times with diverse data.<sup><a href=#user-content-fn-1 aria-describedby=footnote-label data-footnote-ref="" id=user-content-fnref-1>1</a></sup> These flows should neither blow up nor decay to zero over the course of the flow.</p><p>The problem of vanishing or exploding gradients should be familiar to students of deep learning — it’s exactly the issue that incapacitated recurrent neural networks. Fundamentally, this was a problem of coordinating signal propagation in the presence of infinity (in that case, infinite depth). We have an analogous problem on our hands. How might we choose our model hyperparameters to ensure that signal flows well in both directions?</p><h2 id=formalizing-the-training-desiderata>Formalizing the training desiderata<a href=#formalizing-the-training-desiderata class=heading-anchor-link aria-label="Link to Formalizing the training desiderata"><svg aria-hidden=true fill=currentColor viewBox="0 0 24 24"><path d="M2.6 21.4c2 2 5.9 2.9 8.9 0l3.5-3.5-1-1-3.5 3.5c-1.4 1.4-4.2 1.9-6.4-.3s-1.8-5-.3-6.4l3.5-3.5-1-1-3.5 3.5c-3 3-2 6.9 0 8.9ZM21.4 2.6c2 2 2.9 5.9 0 8.9L17.9 15l-1-1 3.5-3.5c1.4-1.4 1.9-4.2-.3-6.4s-5-1.8-6.4-.3l-3.5 3.5-1-1 3.5-3.5c3-3 6.9-2 8.9 0Z"></path><path d="m8.01 14.97 6.93-6.93 1.061 1.06-6.93 6.93z"></path></svg></a></h2><p>We need to be specific about exactly what we want. Let’s use a concrete model: let’s say, a simple MLP with some finite input and output dimension, and hidden dimensions which all go to infinity. We’ll initialize each weight matrix i.i.d. Gaussian with some variance of our choosing. We’ll choose the learning rate separately for each layer too. (This is not the standard way to train networks, but we’ll need the extra hyperparameters.) What does it mean for signal to “flow well?”</p><ol start=0><li>The magnitudes of the elements of each hidden representation should be width-independent (i.e., order-unity).</li><li>After each SGD step, the change in the network outputs shouldn’t scale with the width. This ensures that the loss decreases at a width-independent rate.</li><li>After each SGD step, each representation should update in a way that contributes to optimizing the loss.</li><li>After each SGD step, a layer’s weight update should contribute non-negligibly to the following representation update. (I.e., a representation’s update shouldn’t be dominated by updates to the previous representation.)</li></ol><p>That’s it. These desiderata constrain <em>almost</em> all the free hyperparameters — after the dust settles, there’s exactly one degree of freedom remaining, which controls the size of the updates to the hidden representations. For this reason, this degree of freedom is intimately tied with the model’s ability to learn features from the data.</p><p>Let’s be specific now. Let’s call this remaining degree of freedom the <em>activity</em>, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>α</mi><mo>≡</mo><mi>γ</mi><msup><mi>n</mi><mi>r</mi></msup></mrow><annotation encoding=application/x-tex>\alpha \equiv \gamma n^r</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4637em></span><span class="mord mathnormal" style=margin-right:.0037em>α</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>≡</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.8588em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.05556em>γ</span><span class=mord><span class="mord mathnormal">n</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.6644em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="mtight reset-size6 size3 sizing"><span class="mord mathnormal mtight" style=margin-right:.02778em>r</span></span></span></span></span></span></span></span></span></span></span>. I’ve already taken the liberty to factor the activity into a part that scales with the width <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">n</span></span></span></span> (with scaling exponent <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>r</mi></mrow><annotation encoding=application/x-tex>r</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02778em>r</span></span></span></span>), and a prefactor <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>γ</mi></mrow><annotation encoding=application/x-tex>\gamma</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.05556em>γ</span></span></span></span> which doesn’t.<sup><a href=#user-content-fn-2 aria-describedby=footnote-label data-footnote-ref="" id=user-content-fnref-2>2</a></sup> The signal propagation arguments in my review paper can only constrain the the scaling part, so I’ll just set <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>γ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>\gamma=1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.05556em>γ</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>1</span></span></span></span> hereforth.</p><p>Actually, we can’t just choose any <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>α</mi></mrow><annotation encoding=application/x-tex>\alpha</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.0037em>α</span></span></span></span>. We’re actually restricted to choose within <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>0</mn><mo>≤</mo><mi>r</mi><mo>≤</mo><mn>1</mn><mi mathvariant=normal>/</mi><mn>2</mn></mrow><annotation encoding=application/x-tex>0 \leq r \leq 1/2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7804em;vertical-align:-.136em></span><span class=mord>0</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>≤</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.7719em;vertical-align:-.136em></span><span class="mord mathnormal" style=margin-right:.02778em>r</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>≤</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord>1/2</span></span></span></span>. This interval is what I called the <em>richness scale</em>; choosing the richness <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>r</mi></mrow><annotation encoding=application/x-tex>r</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02778em>r</span></span></span></span> constitutes a hyperparameter choice which determines whether the model learns rich features. After choosing <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>r</mi></mrow><annotation encoding=application/x-tex>r</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02778em>r</span></span></span></span>, set your hyperparameters according to:</p><img decoding=async height=184 loading=lazy src=/_astro/stp-gauge.DebZgcCv_1LPVDg.webp width=728><p>and you can be sure that all our training criteria are satisfied. Specfically, choosing <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>r</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=application/x-tex>r=0</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02778em>r</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>0</span></span></span></span> is called <em>neural tangent parameterization</em> (NTP), and your network will train lazily in the kernel regime, where dynamics are linear and the model converges to the kernel regression predictor. On the other hand, choosing <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>r</mi><mo>=</mo><mn>1</mn><mi mathvariant=normal>/</mi><mn>2</mn></mrow><annotation encoding=application/x-tex>r=1/2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02778em>r</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord>1/2</span></span></span></span> is called <em>maximal update parameterization</em> (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>μ</mi><mi mathvariant=normal>P</mi></mrow><annotation encoding=application/x-tex>\mu\mathrm{P}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class="mord mathnormal">μ</span><span class="mord mathrm">P</span></span></span></span>), and your network will train actively in the rich regime, where the model learns features from the data.</p><img decoding=async height=901 loading=lazy src=/_astro/richness-scale.UebL2CSy_2nv1ln.webp width=2692><p>At first blush, it seems incredible that you can satisfy all those desiderata <em>without</em> feature learning. How is it possible to train a network whose hidden representations evolve negligibly during training? This is one of infinity’s greatest stunts — in the infinite-width limit, lazy networks learn a task without ever adapting its hidden representations to the task! This is one of the major insights gained from studying the neural tangent kernel.</p><p>But of course, our job as scientists is to develop theory that describes practical networks. So, we should focus our energy on understanding the rich regime.</p><h2 id=gauge-symmetries-and-parameterizations-galore>Gauge symmetries and parameterizations galore<a href=#gauge-symmetries-and-parameterizations-galore class=heading-anchor-link aria-label="Link to Gauge symmetries and parameterizations galore"><svg aria-hidden=true fill=currentColor viewBox="0 0 24 24"><path d="M2.6 21.4c2 2 5.9 2.9 8.9 0l3.5-3.5-1-1-3.5 3.5c-1.4 1.4-4.2 1.9-6.4-.3s-1.8-5-.3-6.4l3.5-3.5-1-1-3.5 3.5c-3 3-2 6.9 0 8.9ZM21.4 2.6c2 2 2.9 5.9 0 8.9L17.9 15l-1-1 3.5-3.5c1.4-1.4 1.9-4.2-.3-6.4s-5-1.8-6.4-.3l-3.5 3.5-1-1 3.5-3.5c3-3 6.9-2 8.9 0Z"></path><path d="m8.01 14.97 6.93-6.93 1.061 1.06-6.93 6.93z"></path></svg></a></h2><p>One last caveat — the literature actually has a whole host of infinite-width parameterizations, most of which don’t match the table above. For example, neither the <a href=https://arxiv.org/abs/1806.07572 rel="nofollow noopener noreferrer external" target=_blank>original NTK paper</a> nor the <a href=https://arxiv.org/abs/2011.14522 rel="nofollow noopener noreferrer external" target=_blank><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>μ</mi><mi mathvariant=normal>P</mi></mrow><annotation encoding=application/x-tex>\mu\mathrm{P}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class="mord mathnormal">μ</span><span class="mord mathrm">P</span></span></span></span> paper</a> use layerwise learning rates. This seems to contradict the claim that there is only one degree of freedom in choosing hyperparameters. What’s going on there?</p><p>The explanation is very straightforward — these other papers introduce extra (redundant) hyperparameters. By redundant, I mean that varying these new hyperparameters does not result in any new training dynamics. Behaviorally, there is still only one degree of freedom (the training richness). The only difference is that there are now multiple ways to scale your hyperparameters to achieve any desired training richness.</p><p>This is exactly analogous to gauge symmetries in physics, where there are redundant degrees of freedom in a physical theory which have no experimentally observable consequences. I call the gauge in the table above “STP gauge.” I call the gauge in the original NTK and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>μ</mi><mi mathvariant=normal>P</mi></mrow><annotation encoding=application/x-tex>\mu\mathrm{P}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class="mord mathnormal">μ</span><span class="mord mathrm">P</span></span></span></span> papers ”<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>μ</mi><mi mathvariant=normal>P</mi></mrow><annotation encoding=application/x-tex>\mu\mathrm{P}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class="mord mathnormal">μ</span><span class="mord mathrm">P</span></span></span></span> gauge.” I call the gauge in <a href=https://arxiv.org/abs/2205.09653 rel="nofollow noopener noreferrer external" target=_blank>Bordelon and Pehlevan 2023</a> “rescaling gauge.” These gauges (and their endpoint parameterizations) can be nicely visualized in parameterization space, where the different directions correspond to different ways of scaling your hyperparameters with width. Only one direction (the richness axis) affects training behavior; the other directions are either gauge transformations (yielding behaviorally-equivalent parameterizations) or violate the desiderata (not depicted).</p><img decoding=async height=771 loading=lazy src=/_astro/gauges.CsUHxqpU_20hv8n.webp width=1146><p>See my <a href=https://arxiv.org/abs/2404.19719 rel="nofollow noopener noreferrer external" target=_blank>review paper</a> for more details!</p><figure><img decoding=async height=1420 loading=lazy src=/_astro/derivation.HIoQQ1kr_Z2f4ivd.webp width=2610 alt="A graphical overview of the calculation that gets us all the scalings."><figcaption>A graphical overview of the calculation that gets us all the scalings.</figcaption></figure><section class=footnotes data-footnotes=""><h2 id=footnote-label class=sr-only>Footnotes<a href=#footnote-label class=heading-anchor-link aria-label="Link to Footnotes"><svg aria-hidden=true fill=currentColor viewBox="0 0 24 24"><path d="M2.6 21.4c2 2 5.9 2.9 8.9 0l3.5-3.5-1-1-3.5 3.5c-1.4 1.4-4.2 1.9-6.4-.3s-1.8-5-.3-6.4l3.5-3.5-1-1-3.5 3.5c-3 3-2 6.9 0 8.9ZM21.4 2.6c2 2 2.9 5.9 0 8.9L17.9 15l-1-1 3.5-3.5c1.4-1.4 1.9-4.2-.3-6.4s-5-1.8-6.4-.3l-3.5 3.5-1-1 3.5-3.5c3-3 6.9-2 8.9 0Z"></path><path d="m8.01 14.97 6.93-6.93 1.061 1.06-6.93 6.93z"></path></svg></a></h2><ol><li id=user-content-fn-1><p>Contrast this with, e.g., Hopfield networks, which undergo a dynamical equilibration during inference. (Funnily enough, Hopfield nets just won the Nobel prize in physics.) <a href=#user-content-fnref-1 class=data-footnote-backref aria-label="Back to reference 1" data-footnote-backref="">↩</a></p></li><li id=user-content-fn-2><p>This already contradicts the notation I use in my review paper (oops sorry). I did this because the review paper borrows the notation in <a href=https://arxiv.org/abs/2205.09653 rel="nofollow noopener noreferrer external" target=_blank>Bordelon and Pehlevan 2023</a>, whereas here I’m using the more recent notation from <a href=https://arxiv.org/abs/2410.04642 rel="nofollow noopener noreferrer external" target=_blank>Atanasov et. al. 2024</a>. <a href=#user-content-fnref-2 class=data-footnote-backref aria-label="Back to reference 2" data-footnote-backref="">↩</a></p></li></ol></section></div></article><div id=gsap-post-tags><div class=uno-decorative-line></div><div class="flex flex-wrap gap-x-3 gap-y-3.2"><a href=/tags/science/ class="hover:c-primary border border-secondary/25 ease-out hover:border-secondary/80 hover:font-medium hover:ring-0.2 inline-block px-3.2 py-0.7 relative ring-0 ring-secondary/80 rounded-full transition-[colors,box-shadow]"><span class="flex absolute inset-0 items-center justify-center transition-font-weight whitespace-nowrap">science </span><span class="font-medium inline-block opacity-0" aria-hidden=true>science </span></a><a href=/tags/research/ class="hover:c-primary border border-secondary/25 ease-out hover:border-secondary/80 hover:font-medium hover:ring-0.2 inline-block px-3.2 py-0.7 relative ring-0 ring-secondary/80 rounded-full transition-[colors,box-shadow]"><span class="flex absolute inset-0 items-center justify-center transition-font-weight whitespace-nowrap">research </span><span class="font-medium inline-block opacity-0" aria-hidden=true>research</span></a></div></div></main><footer class="font-navbar leading-1.25em lg:text-3.5 text-3" lg="uno-desktop-column bottom-20"><p><a href=https://github.com/dkarkada class="highlight-hover hover:c-primary after:bottom-0.35em py-0.8 transition-colors" rel="noopener noreferrer" target=_blank>GitHub</a>&nbsp;/ <a href=mailto:dkarkada@berkeley.edu class="highlight-hover hover:c-primary after:bottom-0.35em py-0.8 transition-colors" rel="noopener noreferrer" target=_blank>Email</a>&nbsp;/ <a href=https://x.com/dhruvakarkada class="highlight-hover hover:c-primary after:bottom-0.35em py-0.8 transition-colors" rel="noopener noreferrer" target=_blank>X</a>&nbsp;</p><p>© 2025 Dhruva Karkada</p><p>Powered by <a href=https://astro.build/ class="highlight-hover hover:c-primary after:bottom-0.35em py-0.8 transition-colors" rel="noopener noreferrer" target=_blank>Astro</a> and <a href=https://github.com/radishzzz/astro-theme-retypeset class="highlight-hover hover:c-primary after:bottom-0.35em py-0.8 transition-colors" rel="noopener noreferrer" target=_blank>Retypeset</a></p></footer></div><script type=module src=/_astro/GsapAnimation.astro_astro_type_script_index_0_lang.D3crq355.js></script><script>const SOUND_TYPES={CLICK:"tap",TYPING:"type"},CLICK_TARGETS=["#language-switcher","#theme-toggle-button"],TYPING_TARGETS=["#wl-nick","#wl-mail","#wl-link","#wl-edit"],IGNORED_KEYS=["Shift","Control","Alt","Meta","Tab","Escape","CapsLock"],CLICK_SELECTOR=CLICK_TARGETS.join(","),TYPING_SELECTOR=TYPING_TARGETS.join(",");class SoundEffectManager{constructor(){this.audioContext=null,this.audioBuffers=new Map,this.isReady=!1,this.isInitializing=!1}async initialize(){if(!this.isReady&&!this.isInitializing){this.isInitializing=!0;try{this.audioContext=new(window.AudioContext||window.webkitAudioContext),await this.preloadAllSounds(),this.isReady=!0}catch(t){console.warn("Audio initialization failed:",t)}finally{this.isInitializing=!1}}}async preloadAllSounds(){const t=Object.values(SOUND_TYPES).flatMap((t=>Array.from({length:5},((e,i)=>this.loadSound(`${t}_0${i+1}`,`/sounds/${t}_0${i+1}.wav`)))));await Promise.allSettled(t)}async loadSound(t,e){try{const i=await fetch(e),a=await i.arrayBuffer(),n=await this.audioContext.decodeAudioData(a);this.audioBuffers.set(t,n)}catch(e){console.warn(`Failed to load ${t}:`,e)}}async playSound(t){if(this.isReady||this.isInitializing||await this.initialize(),this.isReady&&this.audioContext&&0!==this.audioBuffers.size)try{"suspended"===this.audioContext.state&&await this.audioContext.resume();const e=Array.from(this.audioBuffers.entries()).filter((([e])=>e.startsWith(t))).map((([,t])=>t));if(0===e.length)return;const i=e[Math.floor(Math.random()*e.length)],a=this.audioContext.createBufferSource();a.buffer=i;const n=this.audioContext.createGain();n.gain.value=t===SOUND_TYPES.TYPING?.4:.8,a.connect(n),n.connect(this.audioContext.destination),a.start(0)}catch(t){console.warn("Playback failed:",t)}}}const soundManager=new SoundEffectManager;function handleGlobalClick(t){t.target.closest(CLICK_SELECTOR)&&soundManager.playSound(SOUND_TYPES.CLICK)}function handleGlobalKeydown(t){!t.target.closest(TYPING_SELECTOR)||t.ctrlKey||t.altKey||t.metaKey||IGNORED_KEYS.includes(t.key)||soundManager.playSound(SOUND_TYPES.TYPING)}function setupSoundSystem(){window.matchMedia("(max-width: 1023px)").matches||(document.removeEventListener("click",handleGlobalClick),document.removeEventListener("keydown",handleGlobalKeydown),document.addEventListener("click",handleGlobalClick),document.addEventListener("keydown",handleGlobalKeydown))}setupSoundSystem(),document.addEventListener("astro:page-load",setupSoundSystem)</script><script type=module>const s={copy:'<svg\n      viewBox="0 0 24 24"\n      fill="currentColor"\n    >\n      <path d="M6.9.8v18h14.5V.8zm12.8 16h-11v-14h11z"/>\n      <path d="M4.3 21.2V5.6l-1.7.5v17.1h14.3l.6-2z"/>\n    </svg>',success:'<svg\n      viewBox="0 0 24 24"\n      fill="currentColor"\n    >\n      <path d="m23.1 6.4-1.3-1.3L9.4 16.6l-6.3-5.4-1.2 1.2L9.4 20z"/>\n    </svg>'},c=new WeakMap;async function a(e){const t=e.parentElement?.querySelector("pre code");if(!t)return;const n=t.textContent??"";if(n)try{await navigator.clipboard.writeText(n);const t=c.get(e);t&&clearTimeout(t),e.innerHTML=s.success,e.classList.add("copy-success");const o=setTimeout((()=>{e.innerHTML=s.copy,e.classList.remove("copy-success"),c.delete(e)}),1500);c.set(e,o)}catch(e){console.error("Failed to copy code",e?.message??String(e))}}function n(){document.querySelectorAll(".code-copy-button:not([data-initialized])").forEach((e=>{e.innerHTML=s.copy,e.setAttribute("data-initialized","true")}))}document.addEventListener("click",(e=>{if(!(e.target instanceof HTMLElement))return;const t=e.target.closest(".code-copy-button");t&&a(t)}),{passive:!0}),n(),document.addEventListener("astro:page-load",n)</script><script type=module src=/_astro/PhotoSwipe.astro_astro_type_script_index_0_lang.DvZO34Rg.js></script><script type=module>async function m(t){const e=t.dataset.repo;if(!e)return;const n=t.getElementsByClassName("gc-owner-avatar")[0],o=t.getElementsByClassName("gc-repo-description")[0],a=t.getElementsByClassName("gc-stars-count")[0],r=t.getElementsByClassName("gc-forks-count")[0],s=t.getElementsByClassName("gc-license-info")[0];try{const t=await fetch(`https://api.github.com/repos/${e}`);if(!t.ok)return void(o&&(o.textContent="Loading failed."));const c=await t.json();n&&c.owner?.avatar_url&&(n.style.backgroundImage=`url(${c.owner.avatar_url})`),o&&(o.textContent=c.description??"No description"),a&&(a.textContent=new Intl.NumberFormat("en",{notation:"compact",maximumFractionDigits:1}).format(c.stargazers_count??0)),r&&(r.textContent=new Intl.NumberFormat("en",{notation:"compact",maximumFractionDigits:1}).format(c.forks_count??0)),s&&(s.textContent=c.license?.spdx_id??"No License")}catch(t){console.error(`Failed to fetch ${e}:`,t?.message??String(t))}}function l(){const t=document.getElementsByClassName("gc-container");if(0===t.length)return;const e=new IntersectionObserver((t=>{t.forEach((t=>{t.isIntersecting&&(m(t.target),e.unobserve(t.target))}))}),{rootMargin:"200px"});Array.from(t).forEach((t=>e.observe(t)))}l(),document.addEventListener("astro:page-load",l)</script></html>